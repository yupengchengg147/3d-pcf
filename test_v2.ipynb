{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_cluster import knn_graph, knn\n",
    "from torch_geometric.nn import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Global_Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, num_neighbors, num_samples, mlp, witht=True) -> None:\n",
    "        super().__init__()\n",
    "        self.mlp = mlp\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.num_samples = num_samples\n",
    "        self.witht = witht\n",
    "\n",
    "    def forward(self, f1_list, xyz1_list, dbatch):\n",
    "        fea_source, fea_tar = self.wighted_sample(f1_list, xyz1_list, dbatch)\n",
    "        print(\"fea_source shape\", fea_source.shape)\n",
    "        print(\"fea_tar shape\", fea_tar.shape)\n",
    "        tmp = torch.cat([fea_tar, fea_tar-fea_source], dim=2)\n",
    "        print(\"tmp shape\", tmp.shape)\n",
    "        out = torch.max(self.mlp(tmp), dim=-2)[0]\n",
    "        print(\"out shape\", out.shape)\n",
    "        return torch.tanh(out)\n",
    "\n",
    "    def wighted_sample(self, f1_list, xyz1_list, dbatch):\n",
    "        #input: xyz1_list, f1_list\n",
    "        l = len(f1_list)\n",
    "        n, h = f1_list[-1].shape\n",
    "\n",
    "        fea_set = torch.zeros(l-1, n, self.num_neighbors, h)\n",
    "        delta_r_set = torch.zeros(l-1, n, self.num_neighbors)\n",
    "        \n",
    "        anchor = xyz1_list[-1]\n",
    "        for i in range(0, l-1):\n",
    "            idx_anchor, idx_i= knn(x=xyz1_list[i],y=anchor, k=self.num_neighbors, batch_x=dbatch, batch_y=dbatch)\n",
    "            # 每个frame先找 num_neighbors 个点\n",
    "\n",
    "            delta_xyz = (anchor[idx_anchor,:] - xyz1_list[i][idx_i,:]).reshape(-1, self.num_neighbors, 3).contiguous()\n",
    "            delta_r = torch.sqrt(torch.sum(delta_xyz**2, dim=2))\n",
    "            delta_r_set[i,:,:] = delta_r\n",
    "            #可能会用index_operation的问题，待定\n",
    "\n",
    "            fea_set[i,:,:] = f1_list[i][idx_i,:].reshape(-1, self.num_neighbors, h).contiguous()\n",
    "\n",
    "        fea_set = fea_set.view(1, n, -1, h).contiguous().squeeze(0) #[B*N, num_neighbors, h]\n",
    "        delta_r_set = delta_r_set.view(n, -1).contiguous() \n",
    "\n",
    "        #根据delta_r采样， P 正比于 exp(-belta * delta_r)\n",
    "        alpha, belta = 0.5 ,0.5\n",
    "        # belta越小，分布越平滑, \n",
    "        # belta太大的话，跟第一步直接取num_samples个点的效果差不多\n",
    "\n",
    "        print(\"delta_r_set shape\", delta_r_set.shape)\n",
    "        pr_r = torch.softmax(delta_r_set* (-1.*belta), dim=1) # [B*N, num_neighbors * (T-1)]\n",
    "\n",
    "        if self.witht:\n",
    "            delta_t = torch.repeat_interleave(torch.arange(l-1, 0, -1), self.num_neighbors)\n",
    "            delta_t_set = delta_t.unsqueeze(0).repeat(n, 1).contiguous()\n",
    "            print(\"delta_t_set shape\", delta_t_set.shape)\n",
    "            pr_t = torch.softmax(delta_t_set* (-1.*0.5), dim=1) # [B*N, num_neighbors * (T-1)]\n",
    "            p = 0.5 * pr_r + 0.5 * pr_t\n",
    "        else:\n",
    "            p = pr_r\n",
    "        \n",
    "        print(\"p shape\", p.shape)\n",
    "        print(p[0].sum())\n",
    "\n",
    "        idx = torch.multinomial(p, self.num_samples, replacement=False) # [B*N, num_samples * (T-1)]\n",
    "\n",
    "        fea_source = fea_set[torch.arange(n).unsqueeze(1),idx,:] # [B*N, num_samples * (T-1), 64]\n",
    "        _, sum_n, _ = fea_source.shape\n",
    "        fea_tar = f1_list[-1].unsqueeze(1).repeat(1, sum_n, 1) # [B*N, num_samples * (T-1), 64]\n",
    "    \n",
    "        return fea_source, fea_tar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = [torch.randn(2*512, 64) for _ in range(5)]\n",
    "xyz1_list = [torch.randn(2*512, 3) for _ in range(5)]\n",
    "\n",
    "t = torch.LongTensor([0,1])\n",
    "dbatch = torch.repeat_interleave(t, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_r_set shape torch.Size([1024, 40])\n",
      "delta_t_set shape torch.Size([1024, 40])\n",
      "p shape torch.Size([1024, 40])\n",
      "tensor(1.0000)\n",
      "fea_source shape torch.Size([1024, 4, 64])\n",
      "fea_tar shape torch.Size([1024, 4, 64])\n",
      "tmp shape torch.Size([1024, 4, 128])\n",
      "out shape torch.Size([1024, 128])\n"
     ]
    }
   ],
   "source": [
    "gmodel = Global_Encoder(10, 4, MLP([128, 128,128], norm=None), witht=True)\n",
    "\n",
    "out = gmodel(f1_list, xyz1_list, dbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 获取当前 Notebook 文件的路径\n",
    "notebook_path = os.path.abspath('')\n",
    "# 获取父文件夹的路径\n",
    "parent_folder = os.path.dirname(notebook_path)\n",
    "\n",
    "# 使用 IPython 魔术命令设置环境变量\n",
    "%env PYTHONPATH=$PYTHONPATH:{parent_folder}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_cluster import knn_graph, knn\n",
    "from torch import Tensor\n",
    "from typing import Optional, Tuple\n",
    "from torch_geometric.nn import global_max_pool, global_mean_pool, GATv2Conv\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset.kitti_dataset import KittiDataset\n",
    "\n",
    "from pugcn_lib.feature_extractor import InceptionFeatureExtractor\n",
    "from pugcn_lib.upsample import GeneralUpsampler\n",
    "from pugcn_lib.models import Refiner\n",
    "\n",
    "from models.encoder_pn2 import PNT_2\n",
    "from dataset.kitti_dataset_v2 import KittiDataset_2\n",
    "from models.time_series_models import ScaledDotProductAttention, MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "ft3_list = torch.stack([torch.rand(2*512, 256) for i in range(4)], dim=0)\n",
    "print(ft3_list.shape)\n",
    "lstm_3 = nn.LSTM(input_size=256, hidden_size=256*2, num_layers=2, batch_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft3_list[0:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def model_summary(model, input_size):\n",
    "    # 打印模型信息\n",
    "    print(f\"{'='*30} Model Summary {'='*30}\")\n",
    "    print(\"{:<30} {:<25} {:<20}\".format(\"Layer\", \"Parameter Size\", \"Parameters\"))\n",
    "    print(\"=\"*75)\n",
    "    \n",
    "    # 将输入传递到模型，以便计算参数大小\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = torch.randn(*input_size).to(device)\n",
    "    \n",
    "    # 遍历模型的所有层\n",
    "    total_params = 0\n",
    "    total_size = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_params = np.prod(param.size())\n",
    "        total_params += layer_params\n",
    "        total_size += param.numel() * param.element_size()\n",
    "        print(\"{:<30} {:<25} {:<20}\".format(name, str(param.size()), f\"{layer_params:,}\"))\n",
    "    \n",
    "    total_size_mb = total_size / (1024 ** 2)\n",
    "    \n",
    "    print(\"=\"*75)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Total size: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary(lstm_3, (4, 1, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hc = lstm_3(ft3_list)\n",
    "print(\"out.shape: \", out.shape)\n",
    "out[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc[0].shape, hc[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpos_1 = torch.randn(2*1024,3)\n",
    "bpos_5 =torch.randn(2*1024,3)\n",
    "bfea_1 = torch.randn(2*1024,256)\n",
    "bfea_5 =torch.randn(2*1024,256)\n",
    "t = torch.LongTensor([0,1])\n",
    "dbatch = torch.repeat_interleave(t, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds for each element in :obj:`y` the :obj:`k` nearest points in :obj:`x`.\n",
    "index_ex = knn(x=bpos_1,y=bpos_5, k=10, batch_x=dbatch, batch_y=dbatch)\n",
    "index_ex.shape, index_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.randn(2,1)\n",
    "\n",
    "c = torch.cat((a,b), dim=-1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Local_Point_Trans(nn.Module):\n",
    "    def __init__(self,k) -> None:\n",
    "        super().__init__()\n",
    "        self.k = int(k)\n",
    "        self.lin_p = nn.Sequential(\n",
    "            nn.Linear(4, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 256),\n",
    "        )\n",
    "\n",
    "        self.lin_q = nn.Linear(256, 256)\n",
    "        self.lin_k = nn.Linear(256, 256)\n",
    "        self.lin_v = nn.Linear(256, 256)\n",
    "        self.lin_w = nn.Sequential(\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU())\n",
    "        \n",
    "        self.att = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, f0, fea_cur, xyz_i, xyz_last, batch, t_i, t_cur=1.0):\n",
    "\n",
    "        index = knn(x=xyz_i,y=xyz_last, k=self.k, batch_x=batch, batch_y=batch)\n",
    "\n",
    "        idx_last, idx_i = index[0], index[1]\n",
    "\n",
    "        fea_cur = fea_cur[idx_last].reshape(-1, self.k, 256).contiguous()  # [N, k, 256]\n",
    "        f0 = f0[idx_i].reshape(-1, self.k, 256).contiguous()  # [N, k, 256]\n",
    "\n",
    "        # print(\"fea_cur.shape\",fea_cur.shape)\n",
    "        # print(\"f0.shape\",f0.shape)\n",
    "\n",
    "        xyzt_last = torch.cat((xyz_last[idx_last], t_cur * torch.ones_like(xyz_last[idx_last][:,:1])), \n",
    "                               dim=-1).reshape(-1, self.k, 4).contiguous()\n",
    "        xyzt_i = torch.cat((xyz_i[idx_i], t_i * torch.ones_like(xyz_i[idx_i][:,:1])), \n",
    "                           dim=-1).reshape(-1, self.k, 4).contiguous()\n",
    "        # print(\"xyzt_last.shape\",xyzt_last.shape)\n",
    "        # print(\"xyzt_i.shape\",xyzt_i.shape)\n",
    "        pe = xyzt_i - xyzt_last\n",
    "        for i, layer in enumerate(self.lin_p): pe = layer(pe.transpose(1, 2).contiguous()).transpose(1, 2).contiguous() if i == 1 else layer(pe)\n",
    "        w = self.lin_q(fea_cur) - self.lin_k(f0) + pe\n",
    "        # print(\"w.shape\",w.shape)\n",
    "        for i, layer in enumerate(self.lin_w): w = layer(w.transpose(1, 2).contiguous()).transpose(1, 2).contiguous() if i % 3 == 0 else layer(w)\n",
    "        w = self.att(w)\n",
    "        v = self.lin_v(f0) + pe\n",
    "\n",
    "        res = torch.sum((w * v), dim=1)\n",
    "\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpt = Local_Point_Trans(10)\n",
    "res = lpt(bfea_1, bfea_5, bpos_1, bpos_5, dbatch, 0.2)\n",
    "res.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.randn(5, 512, 256)\n",
    "Q = torch.randn(1, 512, 256)\n",
    "V = torch.randn(5, 512, 256)\n",
    "\n",
    "\n",
    "multihead_attn = nn.MultiheadAttention(256, 4)\n",
    "attn_output, attn_output_weights = multihead_attn(Q, K, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output.shape, attn_output_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complete test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.time_series_model_v2 import PC_forecasting_model_0_1\n",
    "encoder_args = {'df':3}\n",
    "att_args = {'num_heads': 4, 'num_neighs': 20}\n",
    "\n",
    "upsampler_args = {\n",
    "    \"upsampler\": \"nodeshuffle\",\n",
    "    \"in_channels\": 256,\n",
    "    \"out_channels\": 64,\n",
    "    \"k\": 40,\n",
    "    \"r\": 16, \n",
    "    \"conv\":\"gatv2\",\n",
    "    \"heads\":4\n",
    "}\n",
    "\n",
    "refiner_kargs = {\n",
    "    \"in_channels\": 64,\n",
    "    \"out_channels\": 3,\n",
    "    \"k\": 30,\n",
    "    \"dilations\": (1,2),\n",
    "    \"add_points\": True\n",
    "}\n",
    "\n",
    "\n",
    "data_config = {'root': \"/home/stud/ding/PC_FC/PC_forecasting/kittiraw/dataset/sequences\", 'npoints': 4096, 'input_num': 5, 'pred_num': 5, 'tr_seqs': ['00']}\n",
    "demo_dataset = KittiDataset_2(root=data_config['root'], npoints=data_config['npoints'], input_num=data_config['input_num'], pred_num=data_config['pred_num'], seqs=data_config['tr_seqs'])\n",
    "train_dataloader = DataLoader(demo_dataset, batch_size=4) # collate_fn=custom_collate_fn\n",
    "bin_xyz, bin_fea, bgt_xyz = next(iter(train_dataloader))\n",
    "\n",
    "pc_fc_model = PC_forecasting_model_0_1(encoder_args, att_args, upsampler_args, refiner_kargs, data_config['npoints'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_xyz[0].shape, bin_fea[0].shape, bgt_xyz[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coa_list, det_list = pc_fc_model(bin_xyz, 5, 'cpu')\n",
    "len(coa_list), len(det_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coa_list[-1].shape, det_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coa_list), len(det_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grid_t112_p38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
